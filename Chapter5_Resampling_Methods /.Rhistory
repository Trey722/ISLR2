misclassified <- sum(confusion_matrix) - sum(diag(confusion_matrix))
validation_error <- misclassified / sum(confusion_matrix)
validation_error
library(ISLR2)
log_reg <-  glm(default ~ income+balance, data=Default, family = "binomial")
train_proportion <- 0.5
# Generate a random sample of indexes
train_index <- sample(1:nrow(Default), size = train_proportion * nrow(Default))
# Create training and testing datasets
train <- Default[train_index, ]
test <- Default[-train_index, ]
train_log_reg <- glm(default ~ income + balance, data = train, family = "binomial")
test$predicted_probs <- predict(log_reg, newdata = test, type = "response")
test$predicted_class <- ifelse(test$predicted_probs > 0.5, "Yes", "No")
confusion_matrix <- table(test$default, test$predicted_class)
misclassified <- sum(confusion_matrix) - sum(diag(confusion_matrix))
validation_error <- misclassified / sum(confusion_matrix)
validation_error
library(ISLR2)
log_reg <-  glm(default ~ income+balance, data=Default, family = "binomial")
train_proportion <- 0.5
# Generate a random sample of indexes
train_index <- sample(1:nrow(Default), size = train_proportion * nrow(Default))
# Create training and testing datasets
train <- Default[train_index, ]
test <- Default[-train_index, ]
train_log_reg <- glm(default ~ income + balance, data = train, family = "binomial")
test$predicted_probs <- predict(log_reg, newdata = test, type = "response")
test$predicted_class <- ifelse(test$predicted_probs > 0.5, "Yes", "No")
confusion_matrix <- table(test$default, test$predicted_class)
misclassified <- sum(confusion_matrix) - sum(diag(confusion_matrix))
validation_error <- misclassified / sum(confusion_matrix)
validation_error
library(ISLR2)
log_reg <-  glm(default ~ income+balance, data=Default, family = "binomial")
train_proportion <- 0.5
for (i in 1:n_repeats) {
# Generate a random sample of indexes
train_index <- sample(1:nrow(Default), size = train_proportion * nrow(Default))
# Create training and testing datasets
train <- Default[train_index, ]
test <- Default[-train_index, ]
train_log_reg <- glm(default ~ income + balance, data = train, family = "binomial")
test$predicted_probs <- predict(log_reg, newdata = test, type = "response")
test$predicted_class <- ifelse(test$predicted_probs > 0.5, "Yes", "No")
confusion_matrix <- table(test$default, test$predicted_class)
misclassified <- sum(confusion_matrix) - sum(diag(confusion_matrix))
validation_error <- misclassified / sum(confusion_matrix)
validation_error
}
library(ISLR2)
log_reg <-  glm(default ~ income+balance, data=Default, family = "binomial")
train_proportion <- 0.5
for (i in 1:3 {
library(ISLR2)
log_reg <-  glm(default ~ income+balance, data=Default, family = "binomial")
train_proportion <- 0.5
for (i in 1:3) {
# Generate a random sample of indexes
train_index <- sample(1:nrow(Default), size = train_proportion * nrow(Default))
# Create training and testing datasets
train <- Default[train_index, ]
test <- Default[-train_index, ]
train_log_reg <- glm(default ~ income + balance, data = train, family = "binomial")
test$predicted_probs <- predict(log_reg, newdata = test, type = "response")
test$predicted_class <- ifelse(test$predicted_probs > 0.5, "Yes", "No")
confusion_matrix <- table(test$default, test$predicted_class)
misclassified <- sum(confusion_matrix) - sum(diag(confusion_matrix))
validation_error <- misclassified / sum(confusion_matrix)
validation_error
}
library(ISLR2)
log_reg <-  glm(default ~ income+balance, data=Default, family = "binomial")
train_proportion <- 0.5
for (i in 1:3) {
# Generate a random sample of indexes
train_index <- sample(1:nrow(Default), size = train_proportion * nrow(Default))
# Create training and testing datasets
train <- Default[train_index, ]
test <- Default[-train_index, ]
train_log_reg <- glm(default ~ income + balance, data = train, family = "binomial")
test$predicted_probs <- predict(log_reg, newdata = test, type = "response")
test$predicted_class <- ifelse(test$predicted_probs > 0.5, "Yes", "No")
confusion_matrix <- table(test$default, test$predicted_class)
misclassified <- sum(confusion_matrix) - sum(diag(confusion_matrix))
validation_error <- misclassified / sum(confusion_matrix)
validation_error
}
library(ISLR2)
log_reg <-  glm(default ~ income+balance, data=Default, family = "binomial")
train_proportion <- 0.5
for (i in 1:3) {
# Generate a random sample of indexes
train_index <- sample(1:nrow(Default), size = train_proportion * nrow(Default))
# Create training and testing datasets
train <- Default[train_index, ]
test <- Default[-train_index, ]
train_log_reg <- glm(default ~ income + balance, data = train, family = "binomial")
test$predicted_probs <- predict(log_reg, newdata = test, type = "response")
test$predicted_class <- ifelse(test$predicted_probs > 0.5, "Yes", "No")
confusion_matrix <- table(test$default, test$predicted_class)
misclassified <- sum(confusion_matrix) - sum(diag(confusion_matrix))
validation_error <- misclassified / sum(confusion_matrix)
print(validation_error)
}
library(ISLR2)
log_reg <-  glm(default ~ income+balance, data=Default, family = "binomial")
train_proportion <- 0.5
vald_error <- numeric(3)
for (i in 1:3) {
# Generate a random sample of indexes
train_index <- sample(1:nrow(Default), size = train_proportion * nrow(Default))
# Create training and testing datasets
train <- Default[train_index, ]
test <- Default[-train_index, ]
train_log_reg <- glm(default ~ income + balance, data = train, family = "binomial")
test$predicted_probs <- predict(log_reg, newdata = test, type = "response")
test$predicted_class <- ifelse(test$predicted_probs > 0.5, "Yes", "No")
confusion_matrix <- table(test$default, test$predicted_class)
misclassified <- sum(confusion_matrix) - sum(diag(confusion_matrix))
validation_error <- misclassified / sum(confusion_matrix)
vald_error[i] <- validation_error
}
vald_error
library(ISLR2)
log_reg <-  glm(default ~ income+balance, data=Default, family = "binomial")
train_proportion <- 0.5
vald_error <- numeric(3)
for (i in 1:3) {
# Generate a random sample of indexes
train_index <- sample(1:nrow(Default), size = train_proportion * nrow(Default))
# Create training and testing datasets
train <- Default[train_index, ]
test <- Default[-train_index, ]
train_log_reg <- glm(default ~ income + balance, data = train, family = "binomial")
test$predicted_probs <- predict(log_reg, newdata = test, type = "response")
test$predicted_class <- ifelse(test$predicted_probs > 0.5, "Yes", "No")
confusion_matrix <- table(test$default, test$predicted_class)
misclassified <- sum(confusion_matrix) - sum(diag(confusion_matrix))
validation_error <- misclassified / sum(confusion_matrix)
vald_error[i] <- validation_error
}
vald_error
# The test error looks to be quite low.
model_with_student <- glm(default ~ income + balance + student, data = train, family = "binomial")
for (i in 1:3) {
# Generate a random sample of indexes
train_index <- sample(1:nrow(Default), size = train_proportion * nrow(Default))
# Create training and testing datasets
train <- Default[train_index, ]
test <- Default[-train_index, ]
train_log_reg <- glm(default ~ income + balance + student, data = train, family = "binomial")
test$predicted_probs <- predict(log_reg, newdata = test, type = "response")
test$predicted_class <- ifelse(test$predicted_probs > 0.5, "Yes", "No")
confusion_matrix <- table(test$default, test$predicted_class)
misclassified <- sum(confusion_matrix) - sum(diag(confusion_matrix))
validation_error <- misclassified / sum(confusion_matrix)
vald_error[i] <- validation_error
}
vald_error
library(ISLR2)
log_reg <-  glm(default ~ income+balance, data=Default, family = "binomial")
train_proportion <- 0.5
vald_error <- numeric(3)
for (i in 1:3) {
# Generate a random sample of indexes
train_index <- sample(1:nrow(Default), size = train_proportion * nrow(Default))
# Create training and testing datasets
train <- Default[train_index, ]
test <- Default[-train_index, ]
train_log_reg <- glm(default ~ income + balance, data = train, family = "binomial")
test$predicted_probs <- predict(log_reg, newdata = test, type = "response")
test$predicted_class <- ifelse(test$predicted_probs > 0.5, "Yes", "No")
confusion_matrix <- table(test$default, test$predicted_class)
misclassified <- sum(confusion_matrix) - sum(diag(confusion_matrix))
validation_error <- misclassified / sum(confusion_matrix)
vald_error[i] <- validation_error
}
mean(vald_error)
# The test error looks to be quite low.
model_with_student <- glm(default ~ income + balance + student, data = train, family = "binomial")
for (i in 1:3) {
# Generate a random sample of indexes
train_index <- sample(1:nrow(Default), size = train_proportion * nrow(Default))
# Create training and testing datasets
train <- Default[train_index, ]
test <- Default[-train_index, ]
train_log_reg <- glm(default ~ income + balance + student, data = train, family = "binomial")
test$predicted_probs <- predict(log_reg, newdata = test, type = "response")
test$predicted_class <- ifelse(test$predicted_probs > 0.5, "Yes", "No")
confusion_matrix <- table(test$default, test$predicted_class)
misclassified <- sum(confusion_matrix) - sum(diag(confusion_matrix))
validation_error <- misclassified / sum(confusion_matrix)
vald_error[i] <- validation_error
}
mean(vald_erro)r
library(ISLR2)
log_reg <-  glm(default ~ income+balance, data=Default, family = "binomial")
train_proportion <- 0.5
vald_error <- numeric(3)
for (i in 1:3) {
# Generate a random sample of indexes
train_index <- sample(1:nrow(Default), size = train_proportion * nrow(Default))
# Create training and testing datasets
train <- Default[train_index, ]
test <- Default[-train_index, ]
train_log_reg <- glm(default ~ income + balance, data = train, family = "binomial")
test$predicted_probs <- predict(log_reg, newdata = test, type = "response")
test$predicted_class <- ifelse(test$predicted_probs > 0.5, "Yes", "No")
confusion_matrix <- table(test$default, test$predicted_class)
misclassified <- sum(confusion_matrix) - sum(diag(confusion_matrix))
validation_error <- misclassified / sum(confusion_matrix)
vald_error[i] <- validation_error
}
mean(vald_error)
# The test error looks to be quite low.
model_with_student <- glm(default ~ income + balance + student, data = train, family = "binomial")
for (i in 1:3) {
# Generate a random sample of indexes
train_index <- sample(1:nrow(Default), size = train_proportion * nrow(Default))
# Create training and testing datasets
train <- Default[train_index, ]
test <- Default[-train_index, ]
train_log_reg <- glm(default ~ income + balance + student, data = train, family = "binomial")
test$predicted_probs <- predict(log_reg, newdata = test, type = "response")
test$predicted_class <- ifelse(test$predicted_probs > 0.5, "Yes", "No")
confusion_matrix <- table(test$default, test$predicted_class)
misclassified <- sum(confusion_matrix) - sum(diag(confusion_matrix))
validation_error <- misclassified / sum(confusion_matrix)
vald_error[i] <- validation_error
}
mean(vald_error)
library(ISLR2)
log_reg <-  glm(default ~ income+balance, data=Default, family = "binomial")
train_proportion <- 0.5
vald_error <- numeric(3)
for (i in 1:10) {
# Generate a random sample of indexes
train_index <- sample(1:nrow(Default), size = train_proportion * nrow(Default))
# Create training and testing datasets
train <- Default[train_index, ]
test <- Default[-train_index, ]
train_log_reg <- glm(default ~ income + balance, data = train, family = "binomial")
test$predicted_probs <- predict(log_reg, newdata = test, type = "response")
test$predicted_class <- ifelse(test$predicted_probs > 0.5, "Yes", "No")
confusion_matrix <- table(test$default, test$predicted_class)
misclassified <- sum(confusion_matrix) - sum(diag(confusion_matrix))
validation_error <- misclassified / sum(confusion_matrix)
vald_error[i] <- validation_error
}
mean(vald_error)
# The test error looks to be quite low.
model_with_student <- glm(default ~ income + balance + student, data = train, family = "binomial")
for (i in 1:10) {
# Generate a random sample of indexes
train_index <- sample(1:nrow(Default), size = train_proportion * nrow(Default))
# Create training and testing datasets
train <- Default[train_index, ]
test <- Default[-train_index, ]
train_log_reg <- glm(default ~ income + balance + student, data = train, family = "binomial")
test$predicted_probs <- predict(log_reg, newdata = test, type = "response")
test$predicted_class <- ifelse(test$predicted_probs > 0.5, "Yes", "No")
confusion_matrix <- table(test$default, test$predicted_class)
misclassified <- sum(confusion_matrix) - sum(diag(confusion_matrix))
validation_error <- misclassified / sum(confusion_matrix)
vald_error[i] <- validation_error
}
mean(vald_error)
# Adding student doesm't seem to change vald_error.
library(ISLR2)
log_reg <-  glm(default ~ income+balance, data=Default, family = "binomial")
train_proportion <- 0.5
vald_error <- numeric(3)
for (i in 1:3) {
# Generate a random sample of indexes
train_index <- sample(1:nrow(Default), size = train_proportion * nrow(Default))
# Create training and testing datasets
train <- Default[train_index, ]
test <- Default[-train_index, ]
train_log_reg <- glm(default ~ income + balance, data = train, family = "binomial")
test$predicted_probs <- predict(log_reg, newdata = test, type = "response")
test$predicted_class <- ifelse(test$predicted_probs > 0.5, "Yes", "No")
confusion_matrix <- table(test$default, test$predicted_class)
misclassified <- sum(confusion_matrix) - sum(diag(confusion_matrix))
validation_error <- misclassified / sum(confusion_matrix)
vald_error[i] <- validation_error
}
mean(vald_error)
# The test error looks to be quite low.
model_with_student <- glm(default ~ income + balance + student, data = train, family = "binomial")
for (i in 1:10) {
# Generate a random sample of indexes
train_index <- sample(1:nrow(Default), size = train_proportion * nrow(Default))
# Create training and testing datasets
train <- Default[train_index, ]
test <- Default[-train_index, ]
train_log_reg <- glm(default ~ income + balance + student, data = train, family = "binomial")
test$predicted_probs <- predict(log_reg, newdata = test, type = "response")
test$predicted_class <- ifelse(test$predicted_probs > 0.5, "Yes", "No")
confusion_matrix <- table(test$default, test$predicted_class)
misclassified <- sum(confusion_matrix) - sum(diag(confusion_matrix))
validation_error <- misclassified / sum(confusion_matrix)
vald_error[i] <- validation_error
}
mean(vald_error)
# Adding student doesm't seem to change vald_error.
log_model <- glm(Direction ~ Lag1 + Lag2, data=Weekly, family = "binomial")
summary(log_model)
log_model <- glm(Direction ~ Lag1 + Lag2, data=Weekly, family = "binomial")
summary(log_model)
glm.fit.1 <- glm(Direction ~ Lag1 + Lag2,data=Weekly[-1,], family = "binomial")
log_model <- glm(Direction ~ Lag1 + Lag2, data=Weekly, family = "binomial")
summary(log_model)
log_model <- glm(Direction ~ Lag1 + Lag2, data= Weekly[-1], family = "binomial")
log_model <- glm(Direction ~ Lag1 + Lag2, data=Weekly, family = "binomial")
summary(log_model)
log_model_minus_one <- glm(Direction ~ Lag1 + Lag2, data= Weekly[-1], family = "binomial")
log_model <- glm(Direction ~ Lag1 + Lag2, data=Weekly, family = "binomial")
summary(log_model)
log_model_minus_one <- glm(Direction ~ Lag1 + Lag2, data= Weekly[-1, ], family = "binomial")
log_model <- glm(Direction ~ Lag1 + Lag2, data=Weekly, family = "binomial")
summary(log_model)
log_model_minus_one <- glm(Direction ~ Lag1 + Lag2, data= Weekly[-1, ], family = "binomial")
first_obs <- data.frame(Lag1 = Weekly$Lag1[1], Lag2 = Weekly$Lag2[1])
predicted_prob <- predict(log_model_minus_one, newdata = first_obs, type = "response")
predicted_class <- ifelse(predicted_prob > 0.5, "Up", "Down")
actual_class <- Weekly$Direction[1]
log_model <- glm(Direction ~ Lag1 + Lag2, data=Weekly, family = "binomial")
summary(log_model)
log_model_minus_one <- glm(Direction ~ Lag1 + Lag2, data= Weekly[-1, ], family = "binomial")
first_obs <- data.frame(Lag1 = Weekly$Lag1[1], Lag2 = Weekly$Lag2[1])
predicted_prob <- predict(log_model_minus_one, newdata = first_obs, type = "response")
predicted_class <- ifelse(predicted_prob > 0.5, "Up", "Down")
actual_class <- Weekly$Direction[1]
predicted_class
actual_class
log_model <- glm(Direction ~ Lag1 + Lag2, data=Weekly, family = "binomial")
summary(log_model)
log_model_minus_one <- glm(Direction ~ Lag1 + Lag2, data= Weekly[-1, ], family = "binomial")
first_obs <- data.frame(Lag1 = Weekly$Lag1[1], Lag2 = Weekly$Lag2[1])
predicted_prob <- predict(log_model_minus_one, newdata = first_obs, type = "response")
predicted_class <- ifelse(predicted_prob > 0.5, "Up", "Down")
actual_class <- Weekly$Direction[1]
predicted_class
Weekly$Direction[1]
log_model <- glm(Direction ~ Lag1 + Lag2, data=Weekly, family = "binomial")
summary(log_model)
log_model_minus_one <- glm(Direction ~ Lag1 + Lag2, data= Weekly[-1, ], family = "binomial")
first_obs <- data.frame(Lag1 = Weekly$Lag1[1], Lag2 = Weekly$Lag2[1])
predicted_prob <- predict(log_model_minus_one, newdata = first_obs, type = "response")
predicted_class <- ifelse(predicted_prob > 0.5, "Up", "Down")
actual_class <- Weekly$Direction[1]
predicted_class
Weekly$Direction[1][0]
log_model <- glm(Direction ~ Lag1 + Lag2, data=Weekly, family = "binomial")
summary(log_model)
log_model_minus_one <- glm(Direction ~ Lag1 + Lag2, data= Weekly[-1, ], family = "binomial")
first_obs <- data.frame(Lag1 = Weekly$Lag1[1], Lag2 = Weekly$Lag2[1])
predicted_prob <- predict(log_model_minus_one, newdata = first_obs, type = "response")
predicted_class <- ifelse(predicted_prob > 0.5, "Up", "Down")
actual_class <- Weekly$Direction[1]
predicted_class
Weekly$Direction[1]
# A.
log_model <- glm(Direction ~ Lag1 + Lag2, data=Weekly, family = "binomial")
summary(log_model)
# B.
log_model_minus_one <- glm(Direction ~ Lag1 + Lag2, data= Weekly[-1, ], family = "binomial")
#C.
first_obs <- data.frame(Lag1 = Weekly$Lag1[1], Lag2 = Weekly$Lag2[1])
predicted_prob <- predict(log_model_minus_one, newdata = first_obs, type = "response")
predicted_class <- ifelse(predicted_prob > 0.5, "Up", "Down")
actual_class <- Weekly$Direction[1]
predicted_class
Weekly$Direction[1]
# My moddel was correcrt
i <- -1
# D
for (i in 1:nrow(Weekly)) {
# i. Fit a model using all but the ith observation
model_loocv <- glm(Direction ~ Lag1 + Lag2, data = Weekly[-i, ], family = "binomial")
# ii. Compute the posterior probability for the ith observation
new_data <- data.frame(Lag1 = Weekly$Lag1[i], Lag2 = Weekly$Lag2[i])
predicted_prob <- predict(model_loocv, newdata = new_data, type = "response")
# iii. Predict whether the market moves up
predicted_class <- ifelse(predicted_prob > 0.5, "Up", "Down")
# iv. Determine if an error was made
actual_class <- Weekly$Direction[i]
errors[i] <- ifelse(predicted_class == actual_class, 0, 1)  # 0 if correct, 1 if error
}
# A.
log_model <- glm(Direction ~ Lag1 + Lag2, data=Weekly, family = "binomial")
summary(log_model)
# B.
log_model_minus_one <- glm(Direction ~ Lag1 + Lag2, data= Weekly[-1, ], family = "binomial")
#C.
first_obs <- data.frame(Lag1 = Weekly$Lag1[1], Lag2 = Weekly$Lag2[1])
predicted_prob <- predict(log_model_minus_one, newdata = first_obs, type = "response")
predicted_class <- ifelse(predicted_prob > 0.5, "Up", "Down")
actual_class <- Weekly$Direction[1]
predicted_class
Weekly$Direction[1]
# My moddel was correcrt
errors <- numeric(nrow(Weekly))
i <- -1
# D
for (i in 1:nrow(Weekly)) {
# i. Fit a model using all but the ith observation
model_loocv <- glm(Direction ~ Lag1 + Lag2, data = Weekly[-i, ], family = "binomial")
# ii. Compute the posterior probability for the ith observation
new_data <- data.frame(Lag1 = Weekly$Lag1[i], Lag2 = Weekly$Lag2[i])
predicted_prob <- predict(model_loocv, newdata = new_data, type = "response")
# iii. Predict whether the market moves up
predicted_class <- ifelse(predicted_prob > 0.5, "Up", "Down")
# iv. Determine if an error was made
actual_class <- Weekly$Direction[i]
errors[i] <- ifelse(predicted_class == actual_class, 0, 1)  # 0 if correct, 1 if error
}
# E Calculate LOOCV error estimate
loocv_error <- mean(errors)
print(paste("LOOCV Test Error Estimate:", round(loocv_error, 4)))
mu_hat <- mean(Boston$medv)
print(mu_hat)
# A.)
mu_hat <- mean(Boston$medv)
print(mu_hat)
# B.)
# Estimate the standard deviation
sd_medv <- sd(Boston$medv)
# Estimate the standard error
n <- nrow(Boston)
se_mu_hat <- sd_medv / sqrt(n)
print(se_mu_hat)
# A.)
mu_hat <- mean(Boston$medv)
print(mu_hat)
# B.)
# Estimate the standard deviation
sd_medv <- sd(Boston$medv)
# Estimate the standard error
n <- nrow(Boston)
se_mu_hat <- sd_medv / sqrt(n)
print(se_mu_hat)
#C.)
# Bootstrap function to calculate mean
set.seed(123)  # For reproducibility
B <- 1000  # Number of bootstrap samples
bootstrap_means <- numeric(B)
for (i in 1:B) {
bootstrap_sample <- sample(Boston$medv, n, replace = TRUE)
bootstrap_means[i] <- mean(bootstrap_sample)
}
# Estimate the standard error from bootstrap
se_bootstrap <- sd(bootstrap_means)
print(se_bootstrap)
# A.)
mu_hat <- mean(Boston$medv)
print(mu_hat)
# B.)
# Estimate the standard deviation
sd_medv <- sd(Boston$medv)
# Estimate the standard error
n <- nrow(Boston)
se_mu_hat <- sd_medv / sqrt(n)
print(se_mu_hat)
#C.)
# Bootstrap function to calculate mean
set.seed(123)  # For reproducibility
B <- 1000  # Number of bootstrap samples
bootstrap_means <- numeric(B)
for (i in 1:B) {
bootstrap_sample <- sample(Boston$medv, n, replace = TRUE)
bootstrap_means[i] <- mean(bootstrap_sample)
}
# Estimate the standard error from bootstrap
se_bootstrap <- sd(bootstrap_means)
print(se_bootstrap)
#D.)
# Confidence interval using bootstrap
conf_interval <- c(mu_hat - 2 * se_bootstrap, mu_hat + 2 * se_bootstrap)
print(conf_interval)
# Compare with t-test
t_test <- t.test(Boston$medv)
print(t_test$conf.int)
#E.)
# Estimate for the median
mu_med <- median(Boston$medv)
print(mu_med)
#F.)
# Bootstrap for median
bootstrap_medians <- numeric(B)
for (i in 1:B) {
bootstrap_sample <- sample(Boston$medv, n, replace = TRUE)
bootstrap_medians[i] <- median(bootstrap_sample)
}
# Estimate the standard error from bootstrap
se_bootstrap_median <- sd(bootstrap_medians)
print(se_bootstrap_median)
#G.)
# Estimate for the 10th percentile
mu_0.1 <- quantile(Boston$medv, 0.1)
print(mu_0.1)
#H.)
# Bootstrap for the 10th percentile
bootstrap_0.1 <- numeric(B)
for (i in 1:B) {
bootstrap_sample <- sample(Boston$medv, n, replace = TRUE)
bootstrap_0.1[i] <- quantile(bootstrap_sample, 0.1)
}
# Estimate the standard error from bootstrap
se_bootstrap_0.1 <- sd(bootstrap_0.1)
print(se_bootstrap_0.1)
