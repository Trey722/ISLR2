x=model.matrix(Apps~. -1, data=train_data)
y=train_data$Apps
fit.ridge=glmnet(x, y, alpha=0)
plot(fit.ridge, xvar="lambda", label = TRUE)
cv.ridge=cv.glmnet(x, y, alpha=0)
#Cross Validation
plot(cv.ridge)
best_lambda <- cv.ridge$lambda.min
ridge_model = glmnet(x, y, alpha = 0, lambda = best_lambda)
MSE <- sum((predictions - train_data)^2) / nrow(train_data)
x_test = model.matrix(Apps ~ . - 1, data = test_data)
predictions = predict(fit.ridge, s = best_lambda, newx = x_test)
MSE <- sum((predictions - train_data)^2) / nrow(train_data)
MSE
MSE <- sum((predictions - train_data$Apps)^2) / nrow(train_data)
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
MSE
RMSE <- sqrt(MSE)
RMSE
coef(ridge_model)
RMSE
library(ISLR2)
library(glmnet)
train_percent <- 0.7
data <- College
set.seed(10)
n <- nrow(data)
train_size <- floor(train_percent * n)
train_indices <- sample(seq_len(n), size = train_size)
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
x=model.matrix(Apps~. -1, data=train_data)
y=train_data$Apps
fit.lasso=glmnet(x, y)
plot(fit.lasso, xvar="lambda", label = TRUE)
cv.lasso=cv.glmnet(x, y)
#Cross Validation
plot(cv.lasso)
lasso_model = glmnet(x, y, alpha = 0, lambda = best_lambda)
x_test = model.matrix(Apps ~ . - 1, data = test_data)
predictions = predict(fit.lasso, s = best_lambda, newx = x_test)
MSE = sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
RMSE
coef(lasso_model)
library(ISLR2)
library(glmnet)
# Set parameters
train_percent <- 0.7
data <- College
set.seed(10)
# Split the data
n <- nrow(data)
train_size <- floor(train_percent * n)
train_indices <- sample(seq_len(n), size = train_size)
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
# Prepare the model matrix
x <- model.matrix(Apps ~ . - 1, data = train_data)
y <- train_data$Apps
# Fit Lasso regression
fit.lasso <- glmnet(x, y, alpha = 1)  # Set alpha = 1 for Lasso
plot(fit.lasso, xvar = "lambda", label = TRUE)
# Cross-validation to find optimal lambda
cv.lasso <- cv.glmnet(x, y, alpha = 1)
plot(cv.lasso)
# Get the best lambda
best_lambda <- cv.lasso$lambda.min  # or cv.lasso$lambda.1se
# Fit the Lasso model with the best lambda
lasso_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)
# Prepare test data
x_test <- model.matrix(Apps ~ . - 1, data = test_data)
# Make predictions
predictions <- predict(lasso_model, s = best_lambda, newx = x_test)
# Calculate MSE and RMSE
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
# Output RMSE
print(RMSE)
# Get coefficients
coefficients <- coef(lasso_model)
print(coefficients)
library(ISLR2)
library(glmnet)
# Set parameters
train_percent <- 0.7
data <- College
set.seed(10)
# Split the data
n <- nrow(data)
train_size <- floor(train_percent * n)
train_indices <- sample(seq_len(n), size = train_size)
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
# Prepare the model matrix
x <- model.matrix(Apps ~ . - 1, data = train_data)
y <- train_data$Apps
# Fit Lasso regression
fit.lasso <- glmnet(x, y, alpha = 1)  # Set alpha = 1 for Lasso
plot(fit.lasso, xvar = "lambda", label = TRUE)
# Cross-validation to find optimal lambda
cv.lasso <- cv.glmnet(x, y, alpha = 1)
plot(cv.lasso)
# Get the best lambda
best_lambda <- cv.lasso$lambda.max
# Fit the Lasso model with the best lambda
lasso_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)
# Prepare test data
x_test <- model.matrix(Apps ~ . - 1, data = test_data)
# Make predictions
predictions <- predict(lasso_model, s = best_lambda, newx = x_test)
# Calculate MSE and RMSE
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
# Output RMSE
print(RMSE)
# Get coefficients
coefficients <- coef(lasso_model)
print(coefficients)
coefficients <- coef(lasso_model)
# Print non-zero coefficients
non_zero_coefficients <- coefficients[coefficients != 0, ]
library(ISLR2)
library(glmnet)
# Set parameters
train_percent <- 0.7
data <- College
set.seed(10)
# Split the data
n <- nrow(data)
train_size <- floor(train_percent * n)
train_indices <- sample(seq_len(n), size = train_size)
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
# Prepare the model matrix
x <- model.matrix(Apps ~ . - 1, data = train_data)
y <- train_data$Apps
# Fit Lasso regression
fit.lasso <- glmnet(x, y, alpha = 1)  # Set alpha = 1 for Lasso
plot(fit.lasso, xvar = "lambda", label = TRUE)
cv.lasso <- cv.glmnet(x, y, alpha = 1)
plot(cv.lasso)
# Get the best lambda
best_lambda <- cv.lasso$lambda.min
# Fit the Lasso model with the best lambda
lasso_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)
x_test <- model.matrix(Apps ~ . - 1, data = test_data)
# Make predictions
predictions <- predict(lasso_model, s = best_lambda, newx = x_test)
# Calculate MSE and RMSE
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
# Output RMSE
print(RMSE)
# Get coefficients
coefficients <- coef(lasso_model)
# Print non-zero coefficients
non_zero_coefficients <- coefficients[coefficients != 0, ]
c
library(ISLR2)
library(glmnet)
# Set parameters
train_percent <- 0.7
data <- College
set.seed(10)
# Split the data
n <- nrow(data)
train_size <- floor(train_percent * n)
train_indices <- sample(seq_len(n), size = train_size)
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
# Prepare the model matrix
x <- model.matrix(Apps ~ . - 1, data = train_data)
y <- train_data$Apps
# Fit Lasso regression
fit.lasso <- glmnet(x, y, alpha = 1)  # Set alpha = 1 for Lasso
plot(fit.lasso, xvar = "lambda", label = TRUE)
cv.lasso <- cv.glmnet(x, y, alpha = 1)
plot(cv.lasso)
# Get the best lambda
best_lambda <- cv.lasso$lambda.min
# Fit the Lasso model with the best lambda
lasso_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)
x_test <- model.matrix(Apps ~ . - 1, data = test_data)
# Make predictions
predictions <- predict(lasso_model, s = best_lambda, newx = x_test)
# Calculate MSE and RMSE
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
# Output RMSE
print(RMSE)
# Get coefficients
coefficients <- coef(lasso_model)
coefficients
coefficients[coefficients != 0, ]
[coefficients != 0, ]
coefficients[coefficients != 0 ]
[coefficients != 0 ]
coefficients[coefficients != 0 ]
count(coefficients[coefficients != 0 ])
sum(coefficients != 0)
RMSE
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 0.5
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pcr_model <- pcr(Apps ~ ., data = train_data, validation = "CV")
summary(pcr_model)
plot(pcr_model, plottype = "validation")
optimal_ncomp <- which.min(pcr_model$validation$PRESS)
predictions <- predict(pcr_model, newdata = test_data, ncomp = optimal_ncomp)
test_error <- mean((predictions - test_data$Apps)^2)
print(test_error)
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 0.5
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pcr_model <- pcr(Apps ~ ., data = train_data, validation = "CV")
summary(pcr_model)
plot(pcr_model, plottype = "validation")
optimal_ncomp <- which.min(pcr_model$validation$PRESS)
predictions <- predict(pcr_model, newdata = test_data, ncomp = optimal_ncomp)
test_error <- mean((predictions - test_data$Apps)^2)
print(test_error)
test_error <- sum((predictions - test_data$Apps)^2)) / nrow(test_data)
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 0.5
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pcr_model <- pcr(Apps ~ ., data = train_data, validation = "CV")
summary(pcr_model)
plot(pcr_model, plottype = "validation")
optimal_ncomp <- which.min(pcr_model$validation$PRESS)
predictions <- predict(pcr_model, newdata = test_data, ncomp = optimal_ncomp)
optimal_ncomp
MSE
RMSE
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 0.7
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pcr_model <- pcr(Apps ~ ., data = train_data, validation = "CV")
plot(pcr_model, plottype = "validation")
# Finds optimal by minimizeng validation error
optimal_ncomp <- which.min(pcr_model$validation$PRESS)
predictions <- predict(pcr_model, newdata = test_data, ncomp = optimal_ncomp)
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
RMSE
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 0.5
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pcr_model <- pcr(Apps ~ ., data = train_data, validation = "CV")
plot(pcr_model, plottype = "validation")
# Finds optimal by minimizeng validation error
optimal_ncomp <- which.min(pcr_model$validation$PRESS)
predictions <- predict(pcr_model, newdata = test_data, ncomp = optimal_ncomp)
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
RMSE
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 0.7
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pcr_model <- pcr(Apps ~ ., data = train_data, validation = "CV")
plot(pcr_model, plottype = "validation")
# Finds optimal by minimizeng validation error
optimal_ncomp <- which.min(pcr_model$validation$PRESS)
predictions <- predict(pcr_model, newdata = test_data, ncomp = optimal_ncomp)
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
RMSE
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 0.1
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pcr_model <- pcr(Apps ~ ., data = train_data, validation = "CV")
plot(pcr_model, plottype = "validation")
# Finds optimal by minimizeng validation error
optimal_ncomp <- which.min(pcr_model$validation$PRESS)
predictions <- predict(pcr_model, newdata = test_data, ncomp = optimal_ncomp)
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
RMSE
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 0.9
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pcr_model <- pcr(Apps ~ ., data = train_data, validation = "CV")
plot(pcr_model, plottype = "validation")
# Finds optimal by minimizeng validation error
optimal_ncomp <- which.min(pcr_model$validation$PRESS)
predictions <- predict(pcr_model, newdata = test_data, ncomp = optimal_ncomp)
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
RMSE
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 0.99
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pcr_model <- pcr(Apps ~ ., data = train_data, validation = "CV")
plot(pcr_model, plottype = "validation")
# Finds optimal by minimizeng validation error
optimal_ncomp <- which.min(pcr_model$validation$PRESS)
predictions <- predict(pcr_model, newdata = test_data, ncomp = optimal_ncomp)
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
RMSE
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 0.9999
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pcr_model <- pcr(Apps ~ ., data = train_data, validation = "CV")
plot(pcr_model, plottype = "validation")
# Finds optimal by minimizeng validation error
optimal_ncomp <- which.min(pcr_model$validation$PRESS)
predictions <- predict(pcr_model, newdata = test_data, ncomp = optimal_ncomp)
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
RMSE
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 0.99999999
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pcr_model <- pcr(Apps ~ ., data = train_data, validation = "CV")
plot(pcr_model, plottype = "validation")
# Finds optimal by minimizeng validation error
optimal_ncomp <- which.min(pcr_model$validation$PRESS)
predictions <- predict(pcr_model, newdata = test_data, ncomp = optimal_ncomp)
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
RMSE
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 0
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pcr_model <- pcr(Apps ~ ., data = train_data, validation = "CV")
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 1
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pcr_model <- pcr(Apps ~ ., data = train_data, validation = "CV")
plot(pcr_model, plottype = "validation")
# Finds optimal by minimizeng validation error
optimal_ncomp <- which.min(pcr_model$validation$PRESS)
predictions <- predict(pcr_model, newdata = test_data, ncomp = optimal_ncomp)
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
RMSE
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 10
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <-. 10
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 0.1
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pcr_model <- pcr(Apps ~ ., data = train_data, validation = "CV")
plot(pcr_model, plottype = "validation")
# Finds optimal by minimizeng validation error
optimal_ncomp <- which.min(pcr_model$validation$PRESS)
predictions <- predict(pcr_model, newdata = test_data, ncomp = optimal_ncomp)
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
RMSE
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 0.001
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pcr_model <- pcr(Apps ~ ., data = train_data, validation = "CV")
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 0.7
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pcr_model <- pcr(Apps ~ ., data = train_data, validation = "CV")
plot(pcr_model, plottype = "validation")
# Finds optimal by minimizeng validation error
optimal_ncomp <- which.min(pcr_model$validation$PRESS)
predictions <- predict(pcr_model, newdata = test_data, ncomp = optimal_ncomp)
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
RMSE
library(ISLR2)
library(pls)
set.seed(11)
train_fraction <- 0.7
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pls_model <- plsr(Apps ~ ., data = train_data, scale=TRUE, validation = "CV")
summary(pls_model)
plot(pls_model, plottype = "validation")
optimal_ncomp <- which.min(pls_model$validation$PRESS)
predictions <- predict(pls_model, newdata = test_data, ncomp = optimal_ncomp)
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
RMSE
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 0.7
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pls_model <- plsr(Apps ~ ., data = train_data, scale=TRUE, validation = "CV")
summary(pls_model)
plot(pls_model, plottype = "validation")
optimal_ncomp <- which.min(pls_model$validation$PRESS)
predictions <- predict(pls_model, newdata = test_data, ncomp = optimal_ncomp)
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
RMSE
library(ISLR2)
library(pls)
set.seed(11)
train_fraction <- 0.7
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pls_model <- plsr(Apps ~ ., data = train_data, scale=TRUE, validation = "CV")
summary(pls_model)
plot(pls_model, plottype = "validation")
optimal_ncomp <- which.min(pls_model$validation$PRESS)
predictions <- predict(pls_model, newdata = test_data, ncomp = optimal_ncomp)
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
RMSE
library(ISLR2)
library(pls)
set.seed(1)
train_fraction <- 0.7
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pls_model <- plsr(Apps ~ ., data = train_data, scale=TRUE, validation = "CV")
summary(pls_model)
plot(pls_model, plottype = "validation")
optimal_ncomp <- which.min(pls_model$validation$PRESS)
predictions <- predict(pls_model, newdata = test_data, ncomp = optimal_ncomp)
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
RMSE
library(ISLR2)
library(pls)
set.seed(10)
train_fraction <- 0.7
train_indices <- sample(seq_len(nrow(College)), size = floor(train_fraction * nrow(College)))
train_data <- College[train_indices, ]
test_data <- College[-train_indices, ]
pls_model <- plsr(Apps ~ ., data = train_data, scale=TRUE, validation = "CV")
summary(pls_model)
plot(pls_model, plottype = "validation")
optimal_ncomp <- which.min(pls_model$validation$PRESS)
predictions <- predict(pls_model, newdata = test_data, ncomp = optimal_ncomp)
MSE <- sum((predictions - test_data$Apps)^2) / nrow(test_data)
RMSE <- sqrt(MSE)
RMSE
optimal_ncomp
