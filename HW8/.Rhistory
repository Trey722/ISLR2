m2MSE <- getMSE(testdata$Sales, p2)
m2MSE
# Cross vlaidation tree test error is higher then regualr, which seems quite weird to me.
ctrl <- trainControl(method = "cv", number = 5)
m3 <- train(Sales ~ ., data = traindata, method = "rf", trControl = ctrl, importance = TRUE)
p3 <- predict(m3, newdata <- testdata)
m3MSE <- getMSE(testdata$Sales, p3)
m3MSE
library(ISLR2)
library(rpart)
library(rpart.plot)
library(caret)
library(randomForest)
set.seed(10)
# Function gets train and test data index's
getTrainTestIndex <- function(amount)
{
total_numbers <- amount / 2
half <- amount/2
all_indices <- sample(1:amount, size = amount, replace = FALSE)
train_index <- all_indices[1:half]
test_index <- all_indices[half:amount]
return(list(train_index = train_index, test_index = test_index))
}
getMSE <- function(actual, predictions)
{
# This part throws an error
if (length(actual) != length(predictions)) {
stop("Length of actual and predictions must be the same.")
}
mse <- mean((actual - predictions)^2)
return(mse)
}
# A.
data <- Carseats
n <- nrow(data)
indexes <- getTrainTestIndex(n)
traindata <- data[indexes$train_index, ]
testdata <- data[indexes$test_index, ]
# B.)
m1 <- rpart(Sales ~ ., data <- traindata)
rpart.plot(m1, roundint=FALSE)
# The plot shows that shelf location is the best predictor of sales, which makes sense when thinking about how people shop.
p1 <- predict(m1, data <- testdata)
m1MSE <- getMSE(data$Sales, p1)
m1MSE
# C.)
# 5 Fold Cross validation is used
ctrl <- trainControl(method = "cv", number = 5)
m2 <- train(Sales ~ ., data <- traindata, method = "rpart", trControl = ctrl)
p2 <- predict(m2, data <- testdata)
m2MSE <- getMSE(testdata$Sales, p2)
m2MSE
# Cross vlaidation tree test error is higher then regualr, which seems quite weird to me.
ctrl <- trainControl(method = "cv", number = 5)
m3 <- train(Sales ~ ., data = traindata, method = "rf", trControl = ctrl, importance = TRUE)
p3 <- predict(m3, newdata <- testdata)
m3MSE <- getMSE(testdata$Sales, p3)
m3MSE
# m3MSE error = 2.974038
importance_var <- importance(m3$finalModel)
importance_var
library(ISLR2)
library(rpart)
library(rpart.plot)
library(caret)
library(randomForest)
set.seed(10)
# Function gets train and test data index's
getTrainTestIndex <- function(amount)
{
total_numbers <- amount / 2
half <- amount/2
all_indices <- sample(1:amount, size = amount, replace = FALSE)
train_index <- all_indices[1:half]
test_index <- all_indices[half:amount]
return(list(train_index = train_index, test_index = test_index))
}
getMSE <- function(actual, predictions)
{
# This part throws an error
if (length(actual) != length(predictions)) {
stop("Length of actual and predictions must be the same.")
}
mse <- mean((actual - predictions)^2)
return(mse)
}
# A.
data <- Carseats
n <- nrow(data)
indexes <- getTrainTestIndex(n)
traindata <- data[indexes$train_index, ]
testdata <- data[indexes$test_index, ]
# B.)
m1 <- rpart(Sales ~ ., data <- traindata)
rpart.plot(m1, roundint=FALSE)
# The plot shows that shelf location is the best predictor of sales, which makes sense when thinking about how people shop.
p1 <- predict(m1, data <- testdata)
m1MSE <- getMSE(data$Sales, p1)
m1MSE
# C.)
# 5 Fold Cross validation is used
ctrl <- trainControl(method = "cv", number = 5)
m2 <- train(Sales ~ ., data <- traindata, method = "rpart", trControl = ctrl)
p2 <- predict(m2, data <- testdata)
m2MSE <- getMSE(testdata$Sales, p2)
m2MSE
# Cross vlaidation tree test error is higher then regualr, which seems quite weird to me.
# D.)
ctrl <- trainControl(method = "cv", number = 5)
m3 <- train(Sales ~ ., data = traindata, method = "rf", trControl = ctrl, importance = TRUE)
p3 <- predict(m3, newdata <- testdata)
m3MSE <- getMSE(testdata$Sales, p3)
m3MSE
# m3MSE error = 2.974038
importance_var <- importance(m3$finalModel)
importance_var
# E.)
ctrl <- trainControl(method = "cv", number = 5)
rf_model <- train(Sales ~ ., data = traindata, method = "rf",  trControl = ctrl, importance = TRUE)
rf_predictions <- predict(rf_model, newdata = testdata)
# Calculate MSE for the random forest model
rf_MSE <- mean((testdata$Sales - rf_predictions)^2)
rf
importance_rf <- importance(rf_model$finalModel)
importance_rf
ctrl <- trainControl(method = "cv", number = 5)
rf_model <- train(Sales ~ ., data = traindata, method = "rf",  trControl = ctrl, importance = TRUE)
rf_predictions <- predict(rf_model, newdata = testdata)
# Calculate MSE for the random forest model
rf_MSE <- mean((testdata$Sales - rf_predictions)^2)
rf
importance_rf <- importance(rf_model$finalModel)
importance_rf
ctrl <- trainControl(method = "cv", number = 5)
rf_model <- train(Sales ~ ., data = traindata, method = "rf",  trControl = ctrl, importance = TRUE)
rf_predictions <- predict(rf_model, newdata = testdata)
# Calculate MSE for the random forest model
rf_MSE <- mean((testdata$Sales - rf_predictions)^2)
rf_MSE
importance_rf <- importance(rf_model$finalModel)
importance_rf
install.packages("dbarts")
ctrl <- trainControl(method = "cv", number = 5)
ctrl <- trainControl(method = "cv", number = 5)
---
title: "HW 8"
library(ISLR2)
library(rpart)
library(rpart.plot)
library(caret)
library(randomForest)
library(dbarts)
set.seed(10)
# Function gets train and test data index's
getTrainTestIndex <- function(amount)
{
total_numbers <- amount / 2
half <- amount/2
all_indices <- sample(1:amount, size = amount, replace = FALSE)
train_index <- all_indices[1:half]
test_index <- all_indices[half:amount]
return(list(train_index = train_index, test_index = test_index))
}
getMSE <- function(actual, predictions)
{
# This part throws an error
if (length(actual) != length(predictions)) {
stop("Length of actual and predictions must be the same.")
}
mse <- mean((actual - predictions)^2)
return(mse)
}
# A.
data <- Carseats
n <- nrow(data)
indexes <- getTrainTestIndex(n)
traindata <- data[indexes$train_index, ]
testdata <- data[indexes$test_index, ]
# B.)
m1 <- rpart(Sales ~ ., data <- traindata)
rpart.plot(m1, roundint=FALSE)
# The plot shows that shelf location is the best predictor of sales, which makes sense when thinking about how people shop.
p1 <- predict(m1, data <- testdata)
m1MSE <- getMSE(data$Sales, p1)
m1MSE
# C.)
# 5 Fold Cross validation is used
ctrl <- trainControl(method = "cv", number = 5)
m2 <- train(Sales ~ ., data <- traindata, method = "rpart", trControl = ctrl)
p2 <- predict(m2, data <- testdata)
m2MSE <- getMSE(testdata$Sales, p2)
m2MSE
# Cross vlaidation tree test error is higher then regualr, which seems quite weird to me.
# D.)
ctrl <- trainControl(method = "cv", number = 5)
m3 <- train(Sales ~ ., data = traindata, method = "rf", trControl = ctrl, importance = TRUE)
p3 <- predict(m3, newdata <- testdata)
m3MSE <- getMSE(testdata$Sales, p3)
m3MSE
# m3MSE error = 2.974038
importance_var <- importance(m3$finalModel)
importance_var
# E.)
ctrl <- trainControl(method = "cv", number = 5)
m4 <- train(Sales ~ ., data = traindata, method = "rf",  trControl = ctrl, importance = TRUE)
p4 <- predict(m4, newdata = testdata)
m4MSE <- getMSE(testdata$Sales, p4)
importance_rf <- importance(m4$finalModel)
importance_rf
ctrl <- trainControl(method = "cv", number = 5)
m4 <- train(Sales ~ ., data = traindata, method = "rf",  trControl = ctrl, importance = TRUE)
p4 <- predict(m4, newdata = testdata)
m4MSE <- getMSE(testdata$Sales, p4)
importance_rf <- importance(m4$finalModel)
importance_rf
ctrl <- trainControl(method = "cv", number = 5)
m4 <- train(Sales ~ ., data = traindata, method = "rf",  trControl = ctrl, importance = TRUE)
p4 <- predict(m4, newdata = testdata)
m4MSE <- getMSE(testdata$Sales, p4)
m4MSE
importance_rf <- importance(m4$finalModel)
importance_rf
m5 <- bart2(Sales ~ ., data = traindata, ntrees = 50, n.burn = 1000, n.samples = 1000)
m5 <- bart2(Sales ~ ., data = traindata, n.samples = 1000)
p5 <- predict(bart_model, newdata <- testdata)
m5 <- bart2(Sales ~ ., data = traindata, n.samples = 1000)
p5 <- predict(m5, newdata <- testdata)
m5 <- bart2(Sales ~ ., data = traindata, n.samples = 1000, keepTrees = FALSE)
p5 <- predict(m5, newdata <- testdata)
m5 <- bart2(Sales ~ ., data = traindata, n.samples = 1000, keepTrees == TRUE)
m5 <- bart2(Sales ~ ., data = traindata, n.samples = 1000)
p5 <- predict(m5, newdata <- testdata)
# Bart Model
m5 <- bart2(Sales ~ ., data = traindata, ntrees = 50, n.burn = 1000, n.samples = 1000, keepTrees = TRUE)
m5 <- bart2(Sales ~ ., data = traindata, n.burn = 1000, n.samples = 1000, keepTrees = TRUE)
p5 <- predict(m5, newdata <- testdata)
m5MSE <- getMSE(testdata$Sales, p5)
m5 <- bart2(Sales ~ ., data = traindata, n.burn = 1000, n.samples = 1000, keepTrees = TRUE)
p5 <- predict(m5, newdata = testdata)
m5MSE <- getMSE(testdata$Sales, p5)
nrow(p5)
nrow(testdata$Sales)
nrow(testdata$Sales)
nrow(testdata)
nrow(p5)
data <- Carseats
n <- nrow(data)
indexes <- getTrainTestIndex(n)
traindata <- data[indexes$train_index, ]
testdata <- data[indexes$test_index, ]
nrow(p5)
nrow(testdata)
m5 <- bart2(Sales ~ ., data = traindata, n.burn = 1000, n.samples = 1000, keepTrees = TRUE)
p5 <- predict(m5, newdata = testdata)
nrow(p5)
nrow(testdata)
m5 <- bart2(Sales ~ ., data = data, n.burn = 1000, n.samples = 1000, keepTrees = TRUE)
p5 <- predict(m5, newdata = testdata)
m5MSE <- getMSE(test$Sales, p5)
m5 <- bart2(Sales ~ ., data = data, n.burn = 1000, n.samples = 1000, keepTrees = TRUE)
p5 <- predict(m5, newdata = testdata)
m5MSE <- getMSE(testdata$Sales, p5)
nrow(p5)
nrow(testdata)
p5[1:200]
data$Sales
data
nrow(data)
nrow(p5)
nrow(data)
m5 <- bart2(Sales ~ ., data = traindata, n.burn = 1000, n.samples = 100, keepTrees = TRUE)
p5 <- predict(m5, testdata)
m5MSE <- getMSE(testdata$Sales, p5)
nrow(p5)
m5 <- bart2(Sales ~ ., data = traindata, n.burn = 1000, n.samples = 50, keepTrees = TRUE)
p5 <- predict(m5, testdata)
nrow(p5)
m5 <- bart2(Sales ~ ., data = traindata, n.burn = 1000, n.samples = 50, keepTrees = TRUE)
p5 <- predict(m5, testdata)
m5MSE <- getMSE(testdata$Sales, p5)
nrow(testdata)
m5 <- bart2(Sales ~ ., data = traindata, n.burn = 1000, n.samples = 50, keepTrees = TRUE)
p5 <- predict(m5, data <- testdata)
m5MSE <- getMSE(testdata$Sales, p5)
nrow(p5)
nrow(testdata)
nrow(testdata) -1
p5 <- predict(m5, data <- testdata)
m5MSE <- getMSE(testdata$Sales[1:200], p5)
m5MSE <- getMSE(testdata$Sales[2:200], p5)
nrow(testdata_n)
testdata_n <- testdata$Sales[2:200]
nrow(testdata_n)
nrow(testdata$Sales)
nrow(testdata$Sales)
nrow(testdata)
nrow(p5)
nrow(testdata[2:200])
nrow(testdata[2:199])
m5 <- bart2(Sales ~ ., data = traindata, n.burn = 1000, n.samples = 50, keepTrees = TRUE)
p5 <- predict(m5, newdata =  <- testdata)
m5 <- bart2(Sales ~ ., data = traindata, n.burn = 1000, n.samples = 50, keepTrees = TRUE)
p5 <- predict(m5, newdata <- testdata)
m5MSE <- getMSE(testdata$Sales, p5)
p5
testdata$Sales
m5 <- bart2(Sales ~ ., data = traindata, n.burn = 1000, n.samples = 50, keepTrees = TRUE)
# Generate predictions
p5 <- predict(m5, newdata = testdata)
# Calculate mean predictions from the samples
p5_mean <- rowMeans(p5)
# Calculate MSE
m5MSE <- mean((testdata$Sales - p5_mean)^2)
# Output the MSE
m5MSE
m5 <- bart2(Sales ~ ., data = traindata, n.burn = 1000, n.samples = 50, keepTrees = TRUE)
p5 <- predict(m5, newdata = testdata)
p5_mean <- rowMeans(p5)
m5MSE <- getMSE(data$Sales, p5_mean)
nrow(p5_mean)
m5 <- bart2(Sales ~ ., data = traindata, n.burn = 1000, n.samples = 50, keepTrees = TRUE)
p5 <- predict(m5, newdata = testdata)
p5_mean <- rowMeans(p5)
nrow(p5_mean)
m5MSE <- mean((testdata$Sales - p5_mean)^2)
m5MSE
m5 <- bart2(Sales ~ ., data = traindata, n.burn = 1000, n.samples = 50, keepTrees = TRUE)
p5 <- predict(m5, newdata = testdata)
m5MSE <- mean((testdata$Sales - p5_mean)^2)
m5MSE
m5 <- bart2(Sales ~ ., data = traindata, n.samples = 100, keepTrees = TRUE)
p5 <- predict(m5, newdata = testdata)
m5MSE <- mean((testdata$Sales - p5_mean)^2)
m5MSE
m5 <- bart2(Sales ~ ., data = traindata, n.samples = 200, keepTrees = TRUE)
p5 <- predict(m5, newdata = testdata)
m5MSE <- mean((testdata$Sales - p5_mean)^2)
m5MSE
m5 <- bart2(Sales ~ ., data = traindata, n.samples = 50, keepTrees = TRUE)
p5 <- predict(m5, newdata = testdata)
m5MSE <- mean((testdata$Sales - p5_mean)^2)
m5MSE
m5 <- bart2(Sales ~ ., data = traindata, n.samples = 50, keepTrees = FALSE)
p5 <- predict(m5, newdata = testdata)
library(ISLR2)
library(rpart)
library(rpart.plot)
library(caret)
library(randomForest)
library(dbarts)
set.seed(10)
# Function gets train and test data index's
getTrainTestIndex <- function(amount)
{
total_numbers <- amount / 2
half <- amount/2
all_indices <- sample(1:amount, size = amount, replace = FALSE)
train_index <- all_indices[1:half]
test_index <- all_indices[half:amount]
return(list(train_index = train_index, test_index = test_index))
}
getMSE <- function(actual, predictions)
{
# This part throws an error
if (length(actual) != length(predictions)) {
stop("Length of actual and predictions must be the same.")
}
mse <- mean((actual - predictions)^2)
return(mse)
}
# A.
data <- Carseats
n <- nrow(data)
indexes <- getTrainTestIndex(n)
traindata <- data[indexes$train_index, ]
testdata <- data[indexes$test_index, ]
# B.)
m1 <- rpart(Sales ~ ., data <- traindata)
rpart.plot(m1, roundint=FALSE)
# The plot shows that shelf location is the best predictor of sales, which makes sense when thinking about how people shop.
p1 <- predict(m1, data <- testdata)
m1MSE <- getMSE(data$Sales, p1)
m1MSE
# C.)
# 5 Fold Cross validation is used
ctrl <- trainControl(method = "cv", number = 5)
m2 <- train(Sales ~ ., data <- traindata, method = "rpart", trControl = ctrl)
p2 <- predict(m2, data <- testdata)
m2MSE <- getMSE(testdata$Sales, p2)
m2MSE
# Cross vlaidation tree test error is higher then regualr, which seems quite weird to me.
# D.)
ctrl <- trainControl(method = "cv", number = 5)
m3 <- train(Sales ~ ., data = traindata, method = "rf", trControl = ctrl, importance = TRUE)
p3 <- predict(m3, newdata <- testdata)
m3MSE <- getMSE(testdata$Sales, p3)
m3MSE
# m3MSE error = 2.974038
importance_var <- importance(m3$finalModel)
importance_var
# E.)
ctrl <- trainControl(method = "cv", number = 5)
m4 <- train(Sales ~ ., data = traindata, method = "rf",  trControl = ctrl, importance = TRUE)
p4 <- predict(m4, newdata = testdata)
m4MSE <- getMSE(testdata$Sales, p4)
m4MSE
important_var_m4 <- importance(m4$finalModel)
important_var_m4
# Random Forest had the lowest MSE so far
# F.)
# Bart Model
m5 <- bart2(Sales ~ ., data = traindata, n.samples = 50, keepTrees = TRUE)
p5 <- predict(m5, newdata = testdata)
m5MSE <- mean((testdata$Sales - p5_mean)^2)
m5MSE
# Error is higest in BART model
data <- Caravan
traindata <- data[1:1000]
data <- Caravan
traindata <- data[1:1000, ]
testdata <- data[1000:2000, ]
library(gbm)
install.packages(gbm)
install.packages("gbm")
m1 <- gbm(Purchase ~ ., data = traindata, shrinkage = 0.01,  n.trees = 1000, verbose = FALSE)
library(gbm)
# A.)
data <- Caravan
traindata <- data[1:1000, ]
testdata <- data[1000:2000, ]
#B.)
m1 <- gbm(Purchase ~ ., data = traindata, shrinkage = 0.01,  n.trees = 1000, verbose = FALSE)
if (is.factor(traindata_cleaned$Purchase)) {
traindata_cleaned$Purchase <- as.numeric(traindata_cleaned$Purchase) - 1
}
if (is.factor(traindata_cleaned$Purchase)) {
traindata$Purchase <- as.numeric(traindata_cleaned$Purchase) - 1
}
if (is.factor(traindata$Purchase)) {
traindata$Purchase <- as.numeric(traindata_cleaned$Purchase) - 1
}
if (is.factor(traindata$Purchase)) {
traindata$Purchase <- as.numeric(traindata$Purchase) - 1
}
if (is.factor(traindata$Purchase)) {
traindata$Purchase <- as.numeric(traindata$Purchase) - 1
}
if (is.factor(traindata$Purchase)) {
traindata$Purchase <- as.numeric(traindata$Purchase) - 1
}
if (is.factor(traindata$Purchase)) {
traindata$Purchase <- as.numeric(traindata$Purchase) - 1
}
if (is.factor(traindata$Purchase)) {
traindata$Purchase <- as.numeric(traindata$Purchase) - 1
}
if (is.factor(traindata$Purchase)) {
traindata$Purchase <- as.numeric(traindata$Purchase) - 1
}
m1 <- gbm(Purchase ~ ., data = traindata, shrinkage = 0.01,  n.trees = 1000, verbose FALSE)
data <- Caravan
traindata <- data[1:1000, ]
testdata <- data[1000:2000, ]
data <- Caravan
head(data)
t <- head(data)
t
m1 <- gbm(Purchase ~ ., data = traindata, shrinkage = 0.01,  n.trees = 1000, verbose FALSE)
library(gbm)
# A.)
data <- Caravan
traindata <- data[1:1000, ]
testdata <- data[1000:2000, ]
#B.)
m1 <- gbm(Purchase ~ .,
data = traindata,
shrinkage = 0.01,
n.trees = 1000,
verbose = FALSE)
traindata$Purchase <- as.numeric(traindata$Purchase) - 1
m1 <- gbm(Purchase ~ .,
data = traindata,
shrinkage = 0.01,
n.trees = 1000,
verbose = FALSE)
library(gbm)
# A.)
data <- Caravan
data$Purchase <- as.numeric(data$Purchase) - 1
traindata <- data[1:1000, ]
testdata <- data[1000:2000, ]
#B.)
m1 <- gbm(Purchase ~ .,
data = traindata,
shrinkage = 0.01,
n.trees = 1000,
verbose = FALSE)
summary(m1)
m1 <- gbm(Purchase ~ .,
data = traindata,
shrinkage = 0.01,
n.trees = 1000,
verbose = FALSE)
summary(m1)
importance()
importance <- summary(m1)
importance
importance <- importance(m1)
importance <- summary(m1)
# Print the importance
print(importance)
